import os
import sys
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer

# **æ‰‹åŠ¨æ·»åŠ  `database/` ç›®å½•åˆ° Python è·¯å¾„**
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "database")))

from database import get_jobs

# **FAISS å’Œæ•°æ®åº“è·¯å¾„**
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "database"))
FAISS_INDEX_PATH = os.path.join(BASE_DIR, "job_embeddings.faiss")
JOB_IDS_PATH = os.path.join(BASE_DIR, "job_ids.npy")

# ç¡®ä¿æ‰€æœ‰ä»£ç ä½¿ç”¨ç›¸åŒçš„æ¨¡å‹
model = SentenceTransformer("all-mpnet-base-v2")  # âœ… ç¡®ä¿ `matching.py` ä¹Ÿç”¨è¿™ä¸ª

# **æ‰“å°åµŒå…¥å‘é‡ç»´åº¦**
test_embedding = model.encode(["test"], convert_to_numpy=True)
print("ğŸ” åµŒå…¥å‘é‡ç»´åº¦:", test_embedding.shape[1])  # âœ… æ‰“å° FAISS éœ€è¦çš„ç»´åº¦

def normalize(vecs):
    """å½’ä¸€åŒ–å‘é‡ï¼Œä½¿å…¶é€‚ç”¨äº Cosine Similarity"""
    norms = np.linalg.norm(vecs, axis=1, keepdims=True)
    return vecs / norms

def build_faiss_index():
    """ä»æ•°æ®åº“åŠ è½½èŒä½æè¿°ï¼Œå¹¶æ„å»º FAISS ä½™å¼¦ç›¸ä¼¼åº¦ç´¢å¼•"""
    jobs = get_jobs()
    jobs = jobs[:1000]
    if not jobs:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°èŒä½æ•°æ®ï¼Œè¯·æ£€æŸ¥ jobs.db æ˜¯å¦å·²å¡«å……æ•°æ®")
        return

    job_descriptions = [job[1] for job in jobs]
    job_ids = [job[0] for job in jobs]

    # è®¡ç®—èŒä½æè¿°çš„åµŒå…¥å‘é‡
    job_embeddings = model.encode(job_descriptions, convert_to_numpy=True)
    job_embeddings = normalize(job_embeddings)  # âœ… åªå½’ä¸€åŒ–ä¸€æ¬¡

    # **åˆ›å»º FAISS ä½™å¼¦ç›¸ä¼¼åº¦ç´¢å¼•**
    dimension = job_embeddings.shape[1]
    index = faiss.IndexFlatIP(dimension)  # âœ… ç¡®ä¿ç»´åº¦åŒ¹é…
    index.add(job_embeddings)

    # å­˜å‚¨ç´¢å¼•å’ŒèŒä½ ID
    faiss.write_index(index, FAISS_INDEX_PATH)
    np.save(JOB_IDS_PATH, job_ids)
    print(f"âœ… {len(jobs)} æ¡èŒä½æ•°æ®å·²å­˜å…¥ FAISSï¼ˆCosine Similarityï¼‰ï¼")

if __name__ == "__main__":
    build_faiss_index()
